{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ann_XOR.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bjp-fKNwyXlw","executionInfo":{"status":"ok","timestamp":1638265766642,"user_tz":-540,"elapsed":15485,"user":{"displayName":"윤영진","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09586788812920305654"}},"outputId":"0897bdd3-5bb0-479e-a128-e0f69fe3ebe5"},"source":["from google.colab import drive\n","drive.mount(\"/gdrive\", force_remount=True)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /gdrive\n"]}]},{"cell_type":"code","metadata":{"id":"zjs6htzXygqR"},"source":["import os\n","import numpy as np\n","from sklearn.metrics import accuracy_score\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import (DataLoader, RandomSampler, TensorDataset)\n","\n","class XOR(nn.Module):\n","\n","  def __init__(self, config):\n","    super(XOR, self).__init__()\n","\n","    # 입력층 노드 수\n","    self.inode = config[\"input_node\"]\n","    # 은닉층 데이터 크기\n","    self.hnode = config[\"hidden_node\"]\n","    # 출력층 노드 수: 분류해야 하는 레이블 수\n","    self.onode = config[\"output_node\"]\n","\n","    # 활성화 함수로 Sigmoid 사용\n","    self.activation = nn.Sigmoid()\n","\n","    # 신경망 설계\n","    self.linear1 = nn.Linear(self.inode, self.hnode, bias=True)\n","    self.linear2 = nn.Linear(self.hnode, self.onode, bias=True)  \n","\n","  def forward(self, input_features):\n","\n","    output1 = self.linear1(input_features)\n","    hypothesis1 = self.activation(output1)\n","\n","    output2 = self.linear2(hypothesis1)\n","    hypothesis2 = self.activation(output2)\n","\n","    return hypothesis2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qr9t2djGy5uO"},"source":["def load_dataset(file):\n","  data = np.loadtxt(file)\n","  print(\"DATA=\",data)\n","  \n","  input_features = data[:,0:-1]\n","  print(\"X=\",input_features)\n","  \n","  labels = np.reshape(data[:,-1],(4,1))\n","  print(\"Y=\",labels)\n","\n"," \n","  input_features = torch.tensor(input_features, dtype=torch.float)\n","  labels = torch.tensor(labels, dtype=torch.float)\n","\n","  return (input_features, labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UnpNrPFby1Yf"},"source":["def train(config):\n","\n","  model = XOR(config).cuda()\n","\n","  (input_features, labels) = load_dataset(config[\"input_data\"])\n","\n","  train_features = TensorDataset(input_features,labels)\n","  train_dataloader = DataLoader(train_features,shuffle=True,batch_size=config[\"batch_size\"])\n","\n","  loss_func = nn.BCELoss()\n","\n","  optimizer = torch.optim.SGD(model.parameters(),lr=config[\"learn_rate\"])\n","\n","\n","  for epoch in range(config[\"epoch\"]+1):\n","\n","    model.train()\n","\n","    costs = []\n","\n","    for(step,batch) in enumerate(train_dataloader) :\n","\n","      batch = tuple(t.cuda() for t in batch)\n","\n","      input_features,labels = batch\n","\n","      optimizer.zero_grad()\n","\n","      hypothesis = model(input_features)\n","      \n","      cost = loss_func(hypothesis,labels)\n","      cost.backward()\n","      optimizer.step()\n","      costs.append(cost.data.item())\n","\n","      if epoch % 100 == 0:\n","        print(\"Average Loss = {0:f}\".format(np.mean(cost)))\n","        torch.save(model.state.dict(),os.path.join(config[\"output_dir\"],\"epoch_{0:d}.pt\".format(epoch)))\n","        do_test(model,train_dataloader)\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-ajzHtDh1aL3"},"source":["def test(config):\n","  model = XOR(config).cuda()\n","\n","  model.load_state_dict(torch.load(os.path.join(config[\"output_dir\"], config[\"model_name\"])))\n","\n","  (features, labels) = load_dataset(config)\n","\n","  test_features = TensorDataset(features,labels)\n","  test_dataloader = DataLoader(test_features,shuffle=true,batch_size=config[\"batch_size\"])\n","\n","  do_test(model,test_dataloader)\n","\n","\n","  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o25u-wwdzuOI"},"source":["def tensor2list(input_tensor):\n","    return input_tensor.cpu().detach().numpy().tolist()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hwpThj6Z2HyO"},"source":["def do_test(model, test_dataloader):\n","\n","  # 평가 모드 셋팅\n","  model.eval()\n","\n","  # Batch 별로 예측값과 정답을 저장할 리스트 초기화\n","  predicts, golds = [], []\n","  \n","  with torch.no_grad():\n","\n","    for step, batch in enumerate(test_dataloader):\n","  \n","      # .cuda()를 통해 메모리에 업로드\n","      batch = tuple(t.cuda() for t in batch)\n","\n","      input_features, labels = batch\n","      hypothesis = model(input_features)\n","     \n","\n","      # ont-hot 표현으로 변경\n","      logits = (hypothesis>0.5).float()\n","      x = tensor2list(logits)\n","      y = tensor2list(labels)\n","\n","      # 예측값과 정답을 리스트에 추가\n","      predicts.extend(x)\n","      golds.extend(y)\n","    \n","    print(\"PRED=\",predicts)\n","    print(\"GOLD=\",golds)\n","    print(\"Accuracy= {0:f}\\n\".format(accuracy_score(golds, predicts)))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"06Smsvo82cHC","colab":{"base_uri":"https://localhost:8080/","height":675},"executionInfo":{"status":"error","timestamp":1638266537327,"user_tz":-540,"elapsed":265,"user":{"displayName":"윤영진","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09586788812920305654"}},"outputId":"614ab18b-e090-4767-fac1-1ab13b9a1c54"},"source":["if(__name__==\"__main__\"):\n","\n","    root_dir = \"/gdrive/My Drive/colab/ann/xor\"\n","    output_dir = os.path.join(root_dir, \"output\")\n","    if not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","\n","    input_data =\"{0:s}/{1:s}\".format(root_dir,\"train.txt\")\n","\n","    config = {\"mode\": \"train\",\n","              \"model_name\":\"epoch_{0:d}.pt\".format(1000),\n","              \"output_dir\":output_dir,\n","              \"input_data\" :input_data,\n","              \"input_node\":2,\n","              \"hidden_node\":10,\n","              \"output_node\":1,\n","              \"learn_rate\":1,\n","              \"batch_size\":4,\n","              \"epoch\":1000,\n","              }\n","\n","    if(config[\"mode\"] == \"train\"):\n","        train(config)\n","    else:\n","        test(config)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["DATA= [[0. 0. 0.]\n"," [0. 1. 1.]\n"," [1. 0. 1.]\n"," [1. 1. 0.]]\n","X= [[0. 0.]\n"," [0. 1.]\n"," [1. 0.]\n"," [1. 1.]]\n","Y= [[0.]\n"," [1.]\n"," [1.]\n"," [0.]]\n"]},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-167b75a87890>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mode\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-29-9a1c8a8527a4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Average Loss = {0:f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"output_dir\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"epoch_{0:d}.pt\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mdo_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mmean\u001b[0;34m(*args, **kwargs)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m   3368\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3369\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3370\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3372\u001b[0m     return _methods._mean(a, axis=axis, dtype=dtype,\n","\u001b[0;31mTypeError\u001b[0m: mean() received an invalid combination of arguments - got (out=NoneType, axis=NoneType, dtype=NoneType, ), but expected one of:\n * (*, torch.dtype dtype)\n * (tuple of ints dim, bool keepdim, *, torch.dtype dtype)\n * (tuple of names dim, bool keepdim, *, torch.dtype dtype)\n"]}]}]}